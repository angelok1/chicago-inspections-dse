{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was loaded with:\n",
    "\n",
    "```bash\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS=notebook ./dse/bin/dse pyspark --num-executors 5 --driver-memory 8g --executor-memory 8g\n",
    "```\n",
    "\n",
    "At this point, we've got several sets of data processed and cleaned. We also have discovered several fields we can use for joining:\n",
    "\n",
    "- license_id\n",
    "- longitude, latitude\n",
    "\n",
    "Longitude and latitude are great candidates for joining crime, sanitation, weather, and inspections. The problem is that it's not reasonable to expect them to fall on exactly the same coordinate.\n",
    "\n",
    "Suppose we divided the city up into a grid and determined the coordinates for the center of each cell. Then, we could determine which sanitation complaints and crimes were committed in the cell, and connect that to inspections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import from_unixtime, count, datediff, lag, sum, coalesce, rank, lit, when,col, udf, to_date, year, mean, month, date_format, array\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from datetime import datetime\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally at the point where we're ready to encode our final set for use in predictive models. Before we go any further it's important to make some observations on our data. We're going to combine crime, weather, santitation complains, license information, and inspections to form a complete model. Weather, crime, and sanitation complaints are all continuous data, meaning that they represent numerical values (like temperature, proportions, and counts). License and inspections contains a few categorical columns (such as license type, month of inspection, etc.). Computationally speaking, the categorical data isn't processable in its current form. We'll need to change that.\n",
    "\n",
    "Now, let's consider the cost of what we're going to do. The continuous data simply needs to be joined to the set. We've already pre-computed the aggregations. The cateogrical data will need to be recoded (think shuffling and mapping in terms of Spark). Let's do the categorical mapping on the licenses and inspections before we join all the data so that we have less data to shuffle around, and encoding will trigger Spark actions.\n",
    "\n",
    "Ok, so what do we need to do to categorical values? Firsr, we'll encode the categorical features with a method called One-Hot encoding. The idea behind that is we'll take a column that looks like this:\n",
    "\n",
    "| month |\n",
    "|---|\n",
    "| 1 |\n",
    "| 2 |\n",
    "| 3 |\n",
    "\n",
    "...and represent it like this:\n",
    "\n",
    "| month_1 | month_2 | month_3 |\n",
    "|---|---|---|\n",
    "| 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 |\n",
    "\n",
    "That has the advantage that it allows us to mathematically process the data in a model. For example, let's use $\\beta$ to represent our variable weights for, say regression model... our formula could look like this:\n",
    "\n",
    "$$\\beta_0 + \\beta_1 \\times month_1 + \\beta_2 \\times month_2 + \\beta_3 \\times month_3$$\n",
    "\n",
    "Keep in mind that categorical features that are already binary (for example reinspection, recent_inspection, etc.) are already where we want them. This only applies to columns that contain multiple categories in them (like inspection_type). Continuous features are fine the way they are because they represent actual number (proportion of failures, the various counts, temperatures, etc.). So, we need to encode `ward, police_district, inspection_type, month, and weekday`.\n",
    "\n",
    "Why not encode those before we stored data in the database? We certainly could have, but conceptually, this kind of data modeling really belongs with the model, not the data. It's fine to create indexes to represent the categories in the database because we can use that to look up values, or create some kind of relationship or universally computable attribute to the category. These one hot encoded features really mean nothing to anyone except the machine models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and Joining Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_inspections = sqlContext.sql(\"select inspection_dt, license_id, city_grid, y, y_fail, canvass,\\\n",
    "complaint, cumulative_failures, cumulative_inspections, days_since_last_inspection, ever_failed, inspection_type,\\\n",
    "license_related,liquor,month,prev_fail,proportion_past_failures,recent_inspection,reinspection,risk,special_event,\\\n",
    "task_force, weekday, ward, police_district from chicago_data.inspections_by_city_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inspections.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode ` month, weekday,` and `risk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"month\", outputCol=\"monthVec\")\n",
    "df_inspections = encoder.transform(df_inspections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"weekday\", outputCol=\"weekdayVec\")\n",
    "df_inspections = encoder.transform(df_inspections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"risk\", outputCol=\"riskVec\")\n",
    "df_inspections = encoder.transform(df_inspections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"ward\", outputCol=\"wardVec\")\n",
    "df_inspections = encoder.transform(df_inspections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"police_district\", outputCol=\"police_districtVec\")\n",
    "df_inspections = encoder.transform(df_inspections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can now drop the original categorical columns\n",
    "df_inspections = df_inspections.drop(\"month\").drop(\"weekday\").drop(\"risk\").drop(\"ward\").drop(\"police_district\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inspection_dt', 'date'),\n",
       " ('license_id', 'string'),\n",
       " ('city_grid', 'int'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('cumulative_failures', 'int'),\n",
       " ('cumulative_inspections', 'int'),\n",
       " ('days_since_last_inspection', 'int'),\n",
       " ('ever_failed', 'int'),\n",
       " ('inspection_type', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('prev_fail', 'int'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('monthVec', 'vector'),\n",
       " ('weekdayVec', 'vector'),\n",
       " ('riskVec', 'vector'),\n",
       " ('wardVec', 'vector'),\n",
       " ('police_districtVec', 'vector')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inspections.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_inspections = df_inspections.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Licenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get the business licenses. You'll see why we cast the districts and wards to `int` in a minute, but keep in mind they're already numerical codes. That's perfect for model encoding... we don't need to StringIndex them. It's also not a bad idea to push that to the SQL layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_licenses = sqlContext.sql(\"select license_id, conditional_approval from chicago_data.licenses\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_licenses = df_licenses.withColumn(\"conditional_approval\", when(col(\"conditional_approval\") == \"Y\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(conditional_approval=1), Row(conditional_approval=0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_licenses.select(col(\"conditional_approval\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('license_id', 'string'), ('conditional_approval', 'int')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_licenses.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, not all inspection licenses are in the license database. However, the crime data is more comprehensive. We'll take the ward and district from the crime data instead. That leaves only conditional approval for us to use from licenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_licenses = df_licenses.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63524"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_licenses.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_inspections.join(df_licenses, on=\"license_id\", how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(conditional_approval=None),\n",
       " Row(conditional_approval=1),\n",
       " Row(conditional_approval=0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.select(col(\"conditional_approval\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full.withColumn(\"conditional_approval\", coalesce(col(\"conditional_approval\"), lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(conditional_approval=1), Row(conditional_approval=0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.select(col(\"conditional_approval\")).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('license_id', 'string'),\n",
       " ('inspection_dt', 'date'),\n",
       " ('city_grid', 'int'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('cumulative_failures', 'int'),\n",
       " ('cumulative_inspections', 'int'),\n",
       " ('days_since_last_inspection', 'int'),\n",
       " ('ever_failed', 'int'),\n",
       " ('inspection_type', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('prev_fail', 'int'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('monthVec', 'vector'),\n",
       " ('weekdayVec', 'vector'),\n",
       " ('riskVec', 'vector'),\n",
       " ('wardVec', 'vector'),\n",
       " ('police_districtVec', 'vector'),\n",
       " ('conditional_approval', 'int')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_full = df_full.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|RDD Name|\tStorage Level|\tCached Partitions|\tFraction Cached|\tSize in Memory|\tSize on Disk|\n",
    "|---|---|---|---|---|---|\n",
    "|*Project [license_id#979, cast(cast(ward#1004 as decimal(20,0)) as int) AS ward#1012, cast(cast(police_district#1000 as decimal(20,0)) as int) AS police_district#1013, C...\t|Memory Deserialized 1x Replicated\t|13\t|100%\t|869.8 KB\t|0.0 B|\n",
    "|*Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@42aa2539 chicago_data.inspections_by_city_grid[inspection_dt#2,license_id#1,...\t|Memory Deserialized 1x Replicated\t|13\t|100%\t|2.3 MB\t|0.0 B|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_theft = sqlContext.sql(\"select id, city_grid from chicago_data.crime_by_type where primary_type = 'THEFT'\")\n",
    "df_burglary = sqlContext.sql(\"select id, city_grid from chicago_data.crime_by_type where primary_type = 'BURGLARY'\")\n",
    "df_other = sqlContext.sql(\"select id, city_grid from chicago_data.crime_by_type where primary_type in ('BATTERY', 'CRIMINAL DAMAGE', 'NARCOTICS', 'OTHER OFFENSE', 'ASSAULT', 'DECEPTIVE PRACTICE', 'MOTOR VEHICLE THEFT')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460014"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_theft.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133715"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_burglary.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992913"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll aggregate them by `city_grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_theft = df_theft.groupby(\"city_grid\").count()\\\n",
    "                         .select(col(\"city_grid\"), col(\"count\").alias(\"crime_count_theft\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_burglary = df_burglary.groupby(\"city_grid\").count()\\\n",
    "                         .select(col(\"city_grid\"), col(\"count\").alias(\"crime_count_burglary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_other = df_other.groupby(\"city_grid\").count()\\\n",
    "                         .select(col(\"city_grid\"), col(\"count\").alias(\"crime_count_other\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_crime = df_theft.join(df_burglary, on=\"city_grid\", how=\"left_outer\")\\\n",
    "                .join(df_other, on=\"city_grid\", how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city_grid', 'crime_count_theft', 'crime_count_burglary', 'crime_count_other']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city_grid=9597, crime_count_theft=21175, crime_count_burglary=9714, crime_count_other=63347),\n",
       " Row(city_grid=9898, crime_count_theft=18142, crime_count_burglary=429, crime_count_other=10856),\n",
       " Row(city_grid=9498, crime_count_theft=9376, crime_count_burglary=4071, crime_count_other=29065),\n",
       " Row(city_grid=9399, crime_count_theft=868, crime_count_burglary=315, crime_count_other=2118),\n",
       " Row(city_grid=9695, crime_count_theft=6259, crime_count_burglary=2774, crime_count_other=13822)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.join(df_crime, on=\"city_grid\", how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city_grid', 'int'),\n",
       " ('license_id', 'string'),\n",
       " ('inspection_dt', 'date'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('cumulative_failures', 'int'),\n",
       " ('cumulative_inspections', 'int'),\n",
       " ('days_since_last_inspection', 'int'),\n",
       " ('ever_failed', 'int'),\n",
       " ('inspection_type', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('prev_fail', 'int'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('monthVec', 'vector'),\n",
       " ('weekdayVec', 'vector'),\n",
       " ('riskVec', 'vector'),\n",
       " ('wardVec', 'vector'),\n",
       " ('police_districtVec', 'vector'),\n",
       " ('conditional_approval', 'int'),\n",
       " ('crime_count_theft', 'bigint'),\n",
       " ('crime_count_burglary', 'bigint'),\n",
       " ('crime_count_other', 'bigint')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_full = df_full.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"crime_count_theft\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"crime_count_burglary\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.withColumn(\"crime_count_burglary\", coalesce(col(\"crime_count_burglary\"), lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"crime_count_other\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sanitation = sqlContext.sql(\"select service_request_number, city_grid from chicago_data.sanitation_by_city_grid \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.join(df_sanitation.groupby(\"city_grid\").count().select(col(\"count\").alias(\"sanitation_violation_count\"), col(\"city_grid\")), on=\"city_grid\", how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city_grid', 'int'),\n",
       " ('license_id', 'string'),\n",
       " ('inspection_dt', 'date'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('cumulative_failures', 'int'),\n",
       " ('cumulative_inspections', 'int'),\n",
       " ('days_since_last_inspection', 'int'),\n",
       " ('ever_failed', 'int'),\n",
       " ('inspection_type', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('prev_fail', 'int'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('monthVec', 'vector'),\n",
       " ('weekdayVec', 'vector'),\n",
       " ('riskVec', 'vector'),\n",
       " ('wardVec', 'vector'),\n",
       " ('police_districtVec', 'vector'),\n",
       " ('conditional_approval', 'int'),\n",
       " ('crime_count_theft', 'bigint'),\n",
       " ('crime_count_burglary', 'bigint'),\n",
       " ('crime_count_other', 'bigint'),\n",
       " ('sanitation_violation_count', 'bigint')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"sanitation_violation_count\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.withColumn(\"sanitation_violation_count\", coalesce(col(\"sanitation_violation_count\"), lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"sanitation_violation_count\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_temp = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "               load(keyspace=\"chicago_data\", table=\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DATE', 'date'),\n",
       " ('TMAX', 'int'),\n",
       " ('TMAX_3', 'double'),\n",
       " ('TMAX_5', 'double'),\n",
       " ('TMIN', 'int')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_temp = df_temp.filter(col(\"TMAX_3\").isNotNull() & col(\"TMAX_5\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full.join(df_temp.select(col(\"DATE\").alias(\"inspection_dt\"), col(\"TMAX\"), col(\"TMIN\"), col(\"TMAX_3\"), col(\"TMAX_5\"))\n",
    "                                       , on=\"inspection_dt\", how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"TMAX\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.filter(col(\"TMAX\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"TMAX_3\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"TMAX_5\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.filter(col(\"TMIN\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78120"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.drop(\"license_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inspection_dt', 'date'),\n",
       " ('city_grid', 'int'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('cumulative_failures', 'int'),\n",
       " ('cumulative_inspections', 'int'),\n",
       " ('days_since_last_inspection', 'int'),\n",
       " ('ever_failed', 'int'),\n",
       " ('inspection_type', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('prev_fail', 'int'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('monthVec', 'vector'),\n",
       " ('weekdayVec', 'vector'),\n",
       " ('riskVec', 'vector'),\n",
       " ('wardVec', 'vector'),\n",
       " ('police_districtVec', 'vector'),\n",
       " ('conditional_approval', 'int'),\n",
       " ('crime_count_theft', 'bigint'),\n",
       " ('crime_count_burglary', 'bigint'),\n",
       " ('crime_count_other', 'bigint'),\n",
       " ('sanitation_violation_count', 'bigint'),\n",
       " ('TMAX', 'int'),\n",
       " ('TMIN', 'int'),\n",
       " ('TMAX_3', 'double'),\n",
       " ('TMAX_5', 'double')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_last_60 = df_full.filter(date_format(col(\"inspection_dt\"), \"yyyy-MM-dd\").between(\"2016-09-01\", \"2017-01-01\"))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last_60.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full.filter(date_format(col(\"inspection_dt\"), \"yyyy-MM-dd\").between(\"2009-01-01\", \"2016-09-01\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76899"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_full.drop(\"inspection_dt\")\n",
    "#df_last_60 = df_last_60.drop(\"inspection_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_last_60.write.save('last_60_set', format='parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full.write.save('full_set', format='parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "#sqlContext.read.format('parquet').load('/path/to/file') "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
