{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was loaded with:\n",
    "\n",
    "```bash\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS=notebook ./dse/bin/dse pyspark --num-executors 5 --driver-memory 6g --executor-memory 6g\n",
    "```\n",
    "\n",
    "The general plan is to do some exploration and cleaning in jupyter notebooks, then run our actual models by submitting python scripts and letting the jobs run as we'd expect.\n",
    "\n",
    "We'll clean the data and load them into cassandra tables to be used by the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import max, min, isnull, count, datediff, lag, avg, sum, coalesce, rank, lit, when,col, udf, to_date, year, mean, month, date_format, array\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from datetime import datetime\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already explored the weather. We'll just clean it up by taking the weather station we thought was most important and complete, and create a 3 and 5 day rolling weather average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelo/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (2,3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load climate dataset\n",
    "df_climate = pd.read_csv('data/climate835468.csv')\n",
    "\n",
    "# format datetime string\n",
    "#df_climate['DATE'] =  pd.to_datetime(df_climate['DATE'], format='%Y%m%d')\n",
    "\n",
    "# extract rows for Northerly Island station, drop missing data\n",
    "df_northerlyisland = df_climate[(df_climate['STATION_NAME'] == 'CHICAGO NORTHERLY ISLAND IL US') & (df_climate['TMAX'] != -9999) & (df_climate['TMIN'] != -9999)]\n",
    "\n",
    "# drop all columns except date and temperature\n",
    "df_temperature = df_northerlyisland[['DATE', 'TMAX', 'TMIN']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHCND:US1ILCK0148</td>\n",
       "      <td>OAK LAWN 1.9 SE IL US</td>\n",
       "      <td>182.3</td>\n",
       "      <td>41.6936</td>\n",
       "      <td>-87.729</td>\n",
       "      <td>20100124</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHCND:US1ILCK0148</td>\n",
       "      <td>OAK LAWN 1.9 SE IL US</td>\n",
       "      <td>182.3</td>\n",
       "      <td>41.6936</td>\n",
       "      <td>-87.729</td>\n",
       "      <td>20100308</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHCND:US1ILCK0148</td>\n",
       "      <td>OAK LAWN 1.9 SE IL US</td>\n",
       "      <td>182.3</td>\n",
       "      <td>41.6936</td>\n",
       "      <td>-87.729</td>\n",
       "      <td>20100310</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHCND:US1ILCK0148</td>\n",
       "      <td>OAK LAWN 1.9 SE IL US</td>\n",
       "      <td>182.3</td>\n",
       "      <td>41.6936</td>\n",
       "      <td>-87.729</td>\n",
       "      <td>20100311</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHCND:US1ILCK0148</td>\n",
       "      <td>OAK LAWN 1.9 SE IL US</td>\n",
       "      <td>182.3</td>\n",
       "      <td>41.6936</td>\n",
       "      <td>-87.729</td>\n",
       "      <td>20100312</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATION           STATION_NAME ELEVATION LATITUDE LONGITUDE  \\\n",
       "0  GHCND:US1ILCK0148  OAK LAWN 1.9 SE IL US     182.3  41.6936   -87.729   \n",
       "1  GHCND:US1ILCK0148  OAK LAWN 1.9 SE IL US     182.3  41.6936   -87.729   \n",
       "2  GHCND:US1ILCK0148  OAK LAWN 1.9 SE IL US     182.3  41.6936   -87.729   \n",
       "3  GHCND:US1ILCK0148  OAK LAWN 1.9 SE IL US     182.3  41.6936   -87.729   \n",
       "4  GHCND:US1ILCK0148  OAK LAWN 1.9 SE IL US     182.3  41.6936   -87.729   \n",
       "\n",
       "       DATE  PRCP    SNWD    SNOW  TAVG  TMAX  TMIN    AWND  \n",
       "0  20100124  0.34 -9999.0 -9999.0 -9999 -9999 -9999 -9999.0  \n",
       "1  20100308  0.10 -9999.0 -9999.0 -9999 -9999 -9999 -9999.0  \n",
       "2  20100310  0.08 -9999.0 -9999.0 -9999 -9999 -9999 -9999.0  \n",
       "3  20100311  0.03 -9999.0 -9999.0 -9999 -9999 -9999 -9999.0  \n",
       "4  20100312  0.26 -9999.0 -9999.0 -9999 -9999 -9999 -9999.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE    int64\n",
       "TMAX    int64\n",
       "TMIN    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE    object\n",
       "TMAX     int64\n",
       "TMIN     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature[\"DATE\"] = df_temperature[\"DATE\"].astype(str)\n",
    "df_temperature.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From data exploration, we noted that high temperature appears to be associated with failed outcome. Here, we will extract daily maximum (TMAX) and minimum temperature (TMIN) recorded at CHICAGO NORTHERLY ISLAND station, which represents the most comprehensive record from years 2010 to present and is located closest to the city center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(df_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string2Date = udf (lambda s: datetime.strptime(s, '%Y%m%d'), DateType())\n",
    "df = df.withColumn(\"DATE\", string2Date(df[\"DATE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create some rolling averages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DATE=datetime.date(2011, 6, 4), TMAX=91, TMIN=64),\n",
       " Row(DATE=datetime.date(2011, 6, 5), TMAX=77, TMIN=59),\n",
       " Row(DATE=datetime.date(2011, 6, 6), TMAX=94, TMIN=60),\n",
       " Row(DATE=datetime.date(2011, 6, 7), TMAX=97, TMIN=80),\n",
       " Row(DATE=datetime.date(2011, 6, 8), TMAX=96, TMIN=70),\n",
       " Row(DATE=datetime.date(2011, 6, 9), TMAX=70, TMIN=52)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"DATE\")>='2011-05-28') & (col(\"DATE\")<'2011-06-10')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DATE=datetime.date(2010, 6, 3), TMAX=67, TMIN=59),\n",
       " Row(DATE=datetime.date(2012, 6, 3), TMAX=81, TMIN=61),\n",
       " Row(DATE=datetime.date(2013, 6, 3), TMAX=59, TMIN=48),\n",
       " Row(DATE=datetime.date(2014, 6, 3), TMAX=76, TMIN=63),\n",
       " Row(DATE=datetime.date(2015, 6, 3), TMAX=64, TMIN=52)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col(\"DATE\")=='2011-06-03') | (col(\"DATE\")=='2010-06-03') | (col(\"DATE\")=='2012-06-03')| (col(\"DATE\")=='2013-06-03') | (col(\"DATE\")=='2014-06-03') | (col(\"DATE\")=='2015-06-03') | (col(\"DATE\")=='2010-06-03')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we'll have to make a judgement call. It looks like the days surrounding the missing day might be better than what the same date was year over year. That makes sense intuitively. So, we'll use KNN to fill in the missing dates with values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(DATE)=datetime.date(2010, 1, 1))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(min(col(\"DATE\"))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(DATE)=datetime.date(2016, 10, 31))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(max(col(\"DATE\"))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = date(2010, 1, 1)\n",
    "end = date(2016, 10, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = df.select(\"DATE\").orderBy(\"DATE\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d[\"DATE\"] = pd.to_datetime(d[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = set(date(x.year, x.month, x.day) for x in d[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_set = set(start + timedelta(x) for x in range((end - start).days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2010, 12, 31),\n",
       " datetime.date(2011, 3, 19),\n",
       " datetime.date(2011, 3, 20),\n",
       " datetime.date(2011, 3, 22),\n",
       " datetime.date(2011, 3, 23),\n",
       " datetime.date(2011, 3, 24),\n",
       " datetime.date(2011, 3, 25),\n",
       " datetime.date(2011, 3, 26),\n",
       " datetime.date(2011, 3, 27),\n",
       " datetime.date(2011, 4, 12),\n",
       " datetime.date(2011, 5, 25),\n",
       " datetime.date(2011, 5, 26),\n",
       " datetime.date(2011, 5, 28),\n",
       " datetime.date(2011, 5, 29),\n",
       " datetime.date(2011, 5, 30),\n",
       " datetime.date(2011, 5, 31),\n",
       " datetime.date(2011, 6, 1),\n",
       " datetime.date(2011, 6, 2),\n",
       " datetime.date(2011, 6, 3),\n",
       " datetime.date(2011, 8, 23),\n",
       " datetime.date(2011, 8, 24),\n",
       " datetime.date(2012, 4, 21),\n",
       " datetime.date(2013, 5, 23),\n",
       " datetime.date(2013, 5, 24),\n",
       " datetime.date(2013, 10, 2),\n",
       " datetime.date(2013, 10, 3),\n",
       " datetime.date(2014, 7, 24),\n",
       " datetime.date(2014, 7, 25),\n",
       " datetime.date(2014, 9, 9),\n",
       " datetime.date(2016, 7, 9),\n",
       " datetime.date(2016, 7, 10),\n",
       " datetime.date(2016, 7, 11),\n",
       " datetime.date(2016, 7, 12),\n",
       " datetime.date(2016, 10, 1),\n",
       " datetime.date(2016, 10, 16)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = sorted(date_set - d2)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_int = [10000*x.year + 100*x.month + x.day for x in missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add the days to python\n",
    "missing = pd.DataFrame(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing.columns=[\"DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing[\"dv\"] = missing_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>dv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>20101231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>20110319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-03-20</td>\n",
       "      <td>20110320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-03-22</td>\n",
       "      <td>20110322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-23</td>\n",
       "      <td>20110323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE        dv\n",
       "0  2010-12-31  20101231\n",
       "1  2011-03-19  20110319\n",
       "2  2011-03-20  20110320\n",
       "3  2011-03-22  20110322\n",
       "4  2011-03-23  20110323"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "\n",
    "#this gives us something for the model to predict. It doesn't matter that they are all labels.\n",
    "knn = KNN(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.orderBy(\"DATE\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2 = set(date(x.year, x.month, x.day) for x in df_train[\"DATE\"])\n",
    "df_train[\"dv\"] = [10000*x.year + 100*x.month + x.day for x in d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.head of             DATE  TMAX  TMIN        dv\n",
       "0     2010-01-01    21    10  20141124\n",
       "1     2010-01-02    16     7  20100501\n",
       "2     2010-01-03    24     6  20100808\n",
       "3     2010-01-04    21    13  20110807\n",
       "4     2010-01-05    27    19  20161027\n",
       "5     2010-01-06    25    15  20150910\n",
       "6     2010-01-07    25    18  20151009\n",
       "7     2010-01-08    31    20  20160223\n",
       "8     2010-01-09    26    15  20121004\n",
       "9     2010-01-10    21     6  20120904\n",
       "10    2010-01-11    29    20  20160131\n",
       "11    2010-01-12    33    23  20160715\n",
       "12    2010-01-13    37    22  20100901\n",
       "13    2010-01-14    43    33  20100310\n",
       "14    2010-01-15    36    27  20150729\n",
       "15    2010-01-16    30    26  20111112\n",
       "16    2010-01-17    36    25  20110103\n",
       "17    2010-01-18    33    29  20110216\n",
       "18    2010-01-19    38    30  20130108\n",
       "19    2010-01-20    34    31  20150301\n",
       "20    2010-01-21    36    31  20140505\n",
       "21    2010-01-22    36    34  20100406\n",
       "22    2010-01-23    39    34  20120130\n",
       "23    2010-01-24    48    33  20140411\n",
       "24    2010-01-25    34    21  20111213\n",
       "25    2010-01-26    25    15  20131204\n",
       "26    2010-01-27    25    12  20130609\n",
       "27    2010-01-28    21    10  20151106\n",
       "28    2010-01-29    23    10  20150617\n",
       "29    2010-01-30    27    19  20141213\n",
       "...          ...   ...   ...       ...\n",
       "2431  2016-09-30    63    60  20140903\n",
       "2432  2016-10-02    66    58  20100426\n",
       "2433  2016-10-03    65    60  20111217\n",
       "2434  2016-10-04    69    61  20111022\n",
       "2435  2016-10-05    81    62  20120320\n",
       "2436  2016-10-06    72    62  20140225\n",
       "2437  2016-10-07    72    53  20150723\n",
       "2438  2016-10-08    59    47  20120220\n",
       "2439  2016-10-09    61    51  20100627\n",
       "2440  2016-10-10    65    51  20150808\n",
       "2441  2016-10-11    74    59  20100523\n",
       "2442  2016-10-12    68    47  20110524\n",
       "2443  2016-10-13    54    44  20141023\n",
       "2444  2016-10-14    68    46  20160818\n",
       "2445  2016-10-15    71    55  20151023\n",
       "2446  2016-10-17    83    68  20140324\n",
       "2447  2016-10-18    76    60  20140804\n",
       "2448  2016-10-19    68    57  20121022\n",
       "2449  2016-10-20    59    49  20151212\n",
       "2450  2016-10-21    53    46  20120922\n",
       "2451  2016-10-22    61    44  20100915\n",
       "2452  2016-10-23    73    49  20100126\n",
       "2453  2016-10-24    55    49  20150319\n",
       "2454  2016-10-25    54    47  20160317\n",
       "2455  2016-10-26    52    47  20100408\n",
       "2456  2016-10-27    51    46  20120108\n",
       "2457  2016-10-28    65    44  20111231\n",
       "2458  2016-10-29    71    56  20131218\n",
       "2459  2016-10-30    56    48  20130627\n",
       "2460  2016-10-31    62    45  20151116\n",
       "\n",
       "[2461 rows x 4 columns]>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_knn = knn.fit(df_train[\"dv\"].values.reshape(-1,1), df_train[\"TMAX\"].values)\n",
    "\n",
    "max_vals = pd.DataFrame(fit_knn.predict(missing[\"dv\"].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing[\"TMAX\"] = max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_knn = knn.fit(df_train[\"dv\"].values.reshape(-1,1), df_train[\"TMIN\"].values)\n",
    "\n",
    "min_vals = pd.DataFrame(fit_knn.predict(missing[\"dv\"].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing[\"TMIN\"] = min_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del missing[\"dv\"]\n",
    "del df_train[\"dv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([df_train, missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"TMAX_3\", avg(\"TMAX\").over(Window.orderBy(\"DATE\").rowsBetween(-3,0)))\n",
    "df = df.withColumn(\"TMAX_5\", avg(\"TMAX\").over(Window.orderBy(\"DATE\").rowsBetween(-5,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DATE=datetime.date(2010, 1, 1), TMAX=21.0, TMIN=10.0, TMAX_3=21.0, TMAX_5=21.0),\n",
       " Row(DATE=datetime.date(2010, 1, 2), TMAX=16.0, TMIN=7.0, TMAX_3=18.5, TMAX_5=18.5),\n",
       " Row(DATE=datetime.date(2010, 1, 3), TMAX=24.0, TMIN=6.0, TMAX_3=20.333333333333332, TMAX_5=20.333333333333332),\n",
       " Row(DATE=datetime.date(2010, 1, 4), TMAX=21.0, TMIN=13.0, TMAX_3=20.5, TMAX_5=20.5),\n",
       " Row(DATE=datetime.date(2010, 1, 5), TMAX=27.0, TMIN=19.0, TMAX_3=22.0, TMAX_5=21.8),\n",
       " Row(DATE=datetime.date(2010, 1, 6), TMAX=25.0, TMIN=15.0, TMAX_3=24.25, TMAX_5=22.333333333333332),\n",
       " Row(DATE=datetime.date(2010, 1, 7), TMAX=25.0, TMIN=18.0, TMAX_3=24.5, TMAX_5=23.0),\n",
       " Row(DATE=datetime.date(2010, 1, 8), TMAX=31.0, TMIN=20.0, TMAX_3=27.0, TMAX_5=25.5),\n",
       " Row(DATE=datetime.date(2010, 1, 9), TMAX=26.0, TMIN=15.0, TMAX_3=26.75, TMAX_5=25.833333333333332),\n",
       " Row(DATE=datetime.date(2010, 1, 10), TMAX=21.0, TMIN=6.0, TMAX_3=25.75, TMAX_5=25.833333333333332)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DATE', 'date'),\n",
       " ('TMAX', 'double'),\n",
       " ('TMIN', 'double'),\n",
       " ('TMAX_3', 'double'),\n",
       " ('TMAX_5', 'double')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cql\n",
    "CREATE  KEYSPACE chicago_data \n",
    "   WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor' : 1};\n",
    "```\n",
    "\n",
    "```cql\n",
    "CREATE TABLE chicago_data.temperature (\n",
    "    \"DATE\" date,\n",
    "    \"TMAX\" int,\n",
    "    \"TMIN\" int,\n",
    "    \"TMAX_3\" double,\n",
    "    \"TMAX_5\" double,\n",
    "    PRIMARY KEY (\"DATE\"));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " df.write\\\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .mode('append')\\\n",
    "    .options(table=\"temperature\", keyspace=\"chicago_data\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2496"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
