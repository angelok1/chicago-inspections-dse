{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was loaded with:\n",
    "\n",
    "```bash\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS=notebook ./dse/bin/dse pyspark --num-executors 5 --driver-memory 6g --executor-memory 6g\n",
    "```\n",
    "\n",
    "We've already done some exploration in the Exploration notebook. Now, we'll clean the data and load it into Cassandra for use in MLLib model building jobs later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import count, datediff, lag, sum, coalesce, rank, lit, when,col, udf, to_date, year, mean, month, date_format, array\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from datetime import datetime\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the data is in DSEFS (DSE's Hadoop implementation). This should be reminiscent of the way Hadoop does things. Something like this:\n",
    "\n",
    "```bash\n",
    "./dse fs\n",
    "mkdir datadir\n",
    "put /Users/angelo/chicago/data/Food_Inspections.csv datadir/Food_Inspections.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start working with it... let's load it into the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(\"dsefs:///datadir/Food_Inspections.csv\", sep=\"|\", header=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Risk=None),\n",
       " Row(Risk=u'Risk 1 (High)'),\n",
       " Row(Risk=u'All'),\n",
       " Row(Risk=u'Risk 2 (Medium)'),\n",
       " Row(Risk=u'Risk 3 (Low)')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"Risk\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove the other results rows\n",
    "df = df[(df.Results == 'Pass') | (df.Results == 'Fail') | (df.Results == 'Pass w/ Conditions')]\n",
    "\n",
    "#we only want restaurants\n",
    "df = df[df[\"Facility Type\"] == \"Restaurant\"]\n",
    "\n",
    "#Clean up our classes\n",
    "#let's set up some classes... 0=fail, 1=pass, 2=pass with conditions\n",
    "Y_col = when(col(\"Results\") == \"Fail\", 0).when(col(\"Results\") == \"Pass\", 1).otherwise(2)\n",
    "df = df.withColumn(\"y\", Y_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll encode our categorial pass/fail in 2 ways... Y is did you pass? Y_fail is did you fail? One is more logically human readable (not so many double negatives) and the other we'll process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_fail = when(col(\"Results\") == \"Fail\", 1).otherwise(0)\n",
    "df = df.withColumn(\"y_fail\", Y_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need city and state (these are only Chicago's inspections), and we don't need the business names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(License #=u'2093906', Risk=u'Risk 2 (Medium)', Zip=u'60615', Inspection Date=u'11/3/16', Inspection Type=u'Canvass', Results=u'Pass', Latitude=u'41.79517545', Longitude=u'-87.59660148', y=1, y_fail=0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns we don't care about\n",
    "df = df.drop('Location') #just a dupe of Latitude/longitude\n",
    "df = df.drop('State') #they're all chicago\n",
    "df = df.drop('City')\n",
    "df = df.drop('Inspection ID') #since we're going to aggregate anyway\n",
    "df = df.drop('DBA Name') #this is in the licenses anyway\n",
    "df = df.drop('AKA Name') #this is in the licenses anyway\n",
    "df = df.drop('Address') #this is in the licenses anyway\n",
    "df = df.drop('Facility Type') #this is in the licenses anyway, and is hand entered here... so very bad data\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15169"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"License #\").distinct().count()\n",
    "#this is bigger than unique businesses, so they have multiple licenses... too bad I don't know the type..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those 78k inspections represent 15k businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding the Facility Type and Inspection Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"Inspection Type\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 64 inspection types, but as we noticed in exploration, there are a ton of duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up these inspection types as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.replace(\n",
    "    ['finish complaint inspection from 5-18-10','CANVASS/SPECIAL EVENT', 'CANVASS FOR RIB FEST', 'CANVASS SPECIAL EVENTS','LIQUOR CATERING', 'Task Force Liquor Catering','SPECIAL TASK FORCE', 'TASKFORCE', 'task force','Complaint-Fire', 'FIRE/COMPLAIN', 'fire complaint','Task force liquor inspection 1474', 'Task Force for liquor 1474','Package Liquor 1474', 'Task Force for liquor 1474', 'TASK FORCE LIQUOR 1474', 'TASK FORCE LIQUOR 1474','TAVERN 1470', 'task force(1470) liquor tavern','Task Force Liquor 1475'],\n",
    "    ['Complaint','CANVASS SPECIAL EVENTS','CANVASS SPECIAL EVENTS','CANVASS SPECIAL EVENTS','Task Force Liquor Catering','Task Force Liquor Catering','Special Task Force','Special Task Force','Special Task Force','Fire Complaint','Fire Complaint','Fire Complaint','TASK FORCE PACKAGE LIQUOR','TASK FORCE PACKAGE LIQUOR','TASK FORCE PACKAGE LIQUOR','TASK FORCE PACKAGE LIQUOR','TASK FORCE PACKAGE LIQUOR','TASK FORCE PACKAGE LIQUOR','Task Force Liquor Tavern','Task Force Liquor Tavern','Task Force Liquor Tavern'],\n",
    "    \"Inspection Type\")\n",
    "\n",
    "df = df.replace(\n",
    "    ['license','CLOSE-UP/COMPLAINT REINSPECTION', 'REINSPECTION OF CLOSE-UP','1315 license reinspection', 'License Re-Inspection','TASK FORCE LIQUOR 1470', 'Task Force 1470 Liquor Tavern', 'TASK FORCE LIQUOR 1470','CANVASS RE INSPECTION OF CLOSE UP','LICENSE TASK FORCE / NOT -FOR-PROFIT CLUB', 'LICENSE TASK FORCE / NOT -FOR-PROFIT CLU','TASK FORCE LIQUOR (1481)','license task 1474','TASK FORCE PACKAGE GOODS 1474'],\n",
    "    ['License','REINSPECTION OF CLOSE-UP','REINSPECTION OF CLOSE-UP','License Reinspection','License Reinspection','Task Force Liquor Tavern','Task Force Liquor Tavern','Task Force Liquor Tavern','REINSPECTION OF CLOSE-UP','Task Force Not-For-Profit Club','Task Force Not-For-Profit Club','TASK FORCE PACKAGE LIQUOR','License-Task Force','License-Task Force'],\n",
    "    \"Inspection Type\")\n",
    "\n",
    "df = df.replace(\n",
    "    ['KIDS CAFE','CANVAS','LICENSE','No entry', 'NO ENTRY', 'no entry','LICENSE CONSULTATION','LICENSE RENEWAL INSPECTION FOR DAYCARE', 'LICENSE RENEWAL FOR DAYCARE',  'LICENSE DAYCARE 1586','TWO PEOPLE ATE AND GOT SICK.', 'Suspected Food Poisoning', 'SFP/Complaint', 'SFP', 'sfp/complaint', 'SFP/COMPLAINT','Suspected Food Poisoning Re-inspection', 'SFP RECENTLY INSPECTED','out ofbusiness', 'OUT OF BUSINESS'],\n",
    "    ['Kids Cafe',\"Canvass\",'License','No Entry', 'No Entry', 'No Entry', 'License consultation','DAY CARE LICENSE RENEWAL','DAY CARE LICENSE RENEWAL','DAY CARE LICENSE RENEWAL','Suspected Food Poisoning','Suspected Food Poisoning','Suspected Food Poisoning','Suspected Food Poisoning','Suspected Food Poisoning','Suspected Food Poisoning','Suspected Food Poisoning Reinspection','Suspected Food Poisoning Reinspection','Out of Business','Out of Business'],\n",
    "    \"Inspection Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll extract some features from these inspection types by one-hot encoding some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(License #=u'2093906', Risk=u'Risk 2 (Medium)', Zip=u'60615', Inspection Date=u'11/3/16', Inspection Type=u'Canvass', Results=u'Pass', Latitude=u'41.79517545', Longitude=u'-87.59660148', y=1, y_fail=0),\n",
       " Row(License #=u'2476569', Risk=u'Risk 1 (High)', Zip=u'60621', Inspection Date=u'11/2/16', Inspection Type=u'License Reinspection', Results=u'Pass', Latitude=u'41.77985559', Longitude=u'-87.64514243', y=1, y_fail=0),\n",
       " Row(License #=u'2476568', Risk=u'Risk 1 (High)', Zip=u'60621', Inspection Date=u'11/2/16', Inspection Type=u'License Reinspection', Results=u'Pass', Latitude=u'41.77985559', Longitude=u'-87.64514243', y=1, y_fail=0),\n",
       " Row(License #=u'2354431', Risk=u'Risk 1 (High)', Zip=u'60615', Inspection Date=u'11/2/16', Inspection Type=u'Canvass', Results=u'Pass w/ Conditions', Latitude=u'41.80190189', Longitude=u'-87.62192629', y=2, y_fail=0),\n",
       " Row(License #=u'1767714', Risk=u'Risk 1 (High)', Zip=u'60622', Inspection Date=u'11/2/16', Inspection Type=u'Complaint', Results=u'Fail', Latitude=u'41.91038686', Longitude=u'-87.67683124', y=0, y_fail=1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cache the data often here... don't believe me? comment them out and give it a shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[License #: string, Risk: string, Zip: string, Inspection Date: string, Inspection Type: string, Results: string, Latitude: string, Longitude: string, y: int, y_fail: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also categorize them a bit better. We'll make some features by grouping some of the types of inspections. For example, does it matter if this was any type of reinspection? What about a canvassing, are those effective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = when((col(\"Inspection Type\") == 'Complaint Re-Inspection') |\n",
    "             (col(\"Inspection Type\") == 'Canvass Re-Inspection') |\n",
    "             (col(\"Inspection Type\") == 'Complaint-Fire Re-inspection') |\n",
    "             (col(\"Inspection Type\") == 'RECALL INSPECTION') |\n",
    "             (col(\"Inspection Type\") == 'REINSPECTION OF 48 HOUR NOTICE') |\n",
    "             (col(\"Inspection Type\") == 'REINSPECTION') |\n",
    "             (col(\"Inspection Type\") == 'Suspected Food Poisoning Reinspection') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df.withColumn(\"reinspection\", x_col)\n",
    "\n",
    "x_col = when((col(\"Inspection Type\") == 'Recent Inspection') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('recent_inspection', x_col)\n",
    "\n",
    "x_col = when((col(\"Inspection Type\") == 'License-Task Force') |\n",
    "             (col(\"Inspection Type\") == 'Task Force Liquor Tavern') |\n",
    "             (col(\"Inspection Type\") == 'Task Force Liquor Catering') |\n",
    "             (col(\"Inspection Type\") == 'TASK FORCE NIGHT') |\n",
    "             (col(\"Inspection Type\") == 'Special Task Force') |\n",
    "             (col(\"Inspection Type\") == 'TASK FORCE PACKAGE LIQUOR') |\n",
    "             (col(\"Inspection Type\") == 'Task Force Not-For-Profit Club') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('task_force', x_col)\n",
    "\n",
    "x_col = when((col(\"Inspection Type\") == 'Special Events (Festivals)') |\n",
    "             (col(\"Inspection Type\") == 'CANVASS SPECIAL EVENTS') |\n",
    "             (col(\"Inspection Type\") == 'Summer Feeding') |\n",
    "             (col(\"Inspection Type\") == 'TASTE OF CHICAGO') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('special_event', x_col)\n",
    "\n",
    "x_col = when((col(\"Inspection Type\") == 'Canvass') |\n",
    "             (col(\"Inspection Type\") == 'Canvass Re-Inspection') |\n",
    "             (col(\"Inspection Type\") == 'CANVASS SPECIAL EVENTS') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('canvass', x_col)\n",
    "\n",
    "x_col = when((col(\"Inspection Type\") == 'Task Force Liquor Tavern') |\n",
    "             (col(\"Inspection Type\") == 'TASK FORCE PACKAGE LIQUOR') |\n",
    "             (col(\"Inspection Type\") == 'Task Force Liquor Catering') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('liquor', x_col)\n",
    "   \n",
    "             \n",
    "x_col = when((col(\"Inspection Type\") == 'Complaint-Fire Re-inspection') |\n",
    "             (col(\"Inspection Type\") == 'Fire Complaint') |\n",
    "             (col(\"Inspection Type\") == 'Short Form Fire-Complaint')  \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('fire', x_col)\n",
    "             \n",
    "x_col = when((col(\"Inspection Type\") == 'Complaint') |\n",
    "             (col(\"Inspection Type\") == 'Complaint Re-Inspection') |\n",
    "             (col(\"Inspection Type\") == 'Short Form Complaint') |\n",
    "             (col(\"Inspection Type\") == 'Complaint-Fire Re-inspection') |\n",
    "             (col(\"Inspection Type\") == 'Short Form Fire-Complaint') |\n",
    "             (col(\"Inspection Type\") == 'SMOKING COMPLAINT') |\n",
    "             (col(\"Inspection Type\") == 'NO ENTRY-SHORT COMPLAINT)') |\n",
    "             (col(\"Inspection Type\") == 'Fire Complaint') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('complaint', x_col)\n",
    "\n",
    "                          \n",
    "x_col = when((col(\"Inspection Type\") == 'License') |\n",
    "             (col(\"Inspection Type\") == 'License Reinspection') |\n",
    "             (col(\"Inspection Type\") == 'OWNER SUSPENDED OPERATION/LICENSE') |\n",
    "             (col(\"Inspection Type\") == 'License Consultation') |\n",
    "             (col(\"Inspection Type\") == 'Pre-License Consultation') |\n",
    "             (col(\"Inspection Type\") == 'DAYCARE LICENSE RENEWAL') |\n",
    "             (col(\"Inspection Type\") == 'LICENSE/NOT READY') |\n",
    "             (col(\"Inspection Type\") == 'LICENSE WRONG ADDRESS') |\n",
    "             (col(\"Inspection Type\") == 'LICENSE REQUEST') |\n",
    "             (col(\"Inspection Type\") == 'License-Task Force') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.withColumn('license_related', x_col)\n",
    "             \n",
    "#df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing empty licenses and duplicate inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.filter((col(\"License #\") != 0) & (col(\"Inspection Type\") != 'Duplicated'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cleanup the set by changing the column names and including what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.select(col(\"License #\").alias(\"license_id\"), col(\"Risk\").alias(\"risk_description\"), \\\n",
    "                 col(\"Zip\").alias(\"zip\"), col(\"Inspection Date\").alias(\"inspection_date_string\"), \\\n",
    "                 col(\"Results\").alias(\"y_description\"), col(\"Latitude\").alias(\"latitude\"), \\\n",
    "                 col(\"Longitude\").alias(\"longitude\"), col(\"y\"), col(\"y_fail\"), col(\"reinspection\"),\\\n",
    "                 col(\"recent_inspection\"), col(\"task_force\"), col(\"special_event\"), col(\"canvass\"), \\\n",
    "                 col(\"liquor\"), col(\"fire\"), col(\"complaint\"), col(\"license_related\"), \\\n",
    "                 col(\"Inspection Type\").alias(\"inspection_type_description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[license_id: string, risk_description: string, zip: string, inspection_date_string: string, y_description: string, latitude: string, longitude: string, y: int, y_fail: int, reinspection: int, recent_inspection: int, task_force: int, special_event: int, canvass: int, liquor: int, fire: int, complaint: int, license_related: int, inspection_type_description: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encode fix risk\n",
    "x_col = when(col(\"risk_description\") == 'Risk 1 (High)', 1) \\\n",
    "        .when(col(\"risk_description\") == 'Risk 2 (Medium)', 2) \\\n",
    "        .otherwise(3)\n",
    "\n",
    "df2 = df2.withColumn(\"risk\", x_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Inspection Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, we have 64 types of inspections. Let's see how many have less than 30 inspections (i.e. how many types of inspections are rare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(inspection_type_description=u'Pre-License Consultation', count=6),\n",
       " Row(inspection_type_description=u'CHANGED COURT DATE', count=1),\n",
       " Row(inspection_type_description=u'TASK FORCE PACKAGE LIQUOR', count=7),\n",
       " Row(inspection_type_description=u'TASK FORCE NOT READY', count=1),\n",
       " Row(inspection_type_description=u'LICENSE/NOT READY', count=1),\n",
       " Row(inspection_type_description=u'Special Events (Festivals)', count=21),\n",
       " Row(inspection_type_description=u'citation re-issued', count=1),\n",
       " Row(inspection_type_description=u'LICENSE REQUEST', count=1),\n",
       " Row(inspection_type_description=u'Not Ready', count=3),\n",
       " Row(inspection_type_description=u'LIQOUR TASK FORCE NOT READY', count=1),\n",
       " Row(inspection_type_description=u'NO ENTRY-SHORT COMPLAINT)', count=1),\n",
       " Row(inspection_type_description=u'CANVASS SPECIAL EVENTS', count=2),\n",
       " Row(inspection_type_description=u'Task Force Liquor Catering', count=2),\n",
       " Row(inspection_type_description=u'Sample Collection', count=1),\n",
       " Row(inspection_type_description=u'REINSPECTION OF CLOSE-UP', count=1),\n",
       " Row(inspection_type_description=u'error save', count=1),\n",
       " Row(inspection_type_description=u'Non-Inspection', count=5),\n",
       " Row(inspection_type_description=u'Special Task Force', count=1),\n",
       " Row(inspection_type_description=u'TASTE OF CHICAGO', count=1),\n",
       " Row(inspection_type_description=u'POSSIBLE FBI', count=1),\n",
       " Row(inspection_type_description=u'RE-INSPECTION OF CLOSE-UP', count=1),\n",
       " Row(inspection_type_description=u'HACCP QUESTIONAIRE', count=1),\n",
       " Row(inspection_type_description=u'expansion', count=1),\n",
       " Row(inspection_type_description=u'Task Force Not-For-Profit Club', count=2),\n",
       " Row(inspection_type_description=u'REINSPECTION', count=1),\n",
       " Row(inspection_type_description=u'CORRECTIVE ACTION', count=1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(col(\"inspection_type_description\")).count().filter(col(\"count\") <= 30).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of those types are used just once or twice. We can imagine that once or twice in 7 years of data isn't going to help our predictive power, so we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = when((col(\"inspection_type_description\") == 'Pre-License Consultation') |\n",
    "             (col(\"inspection_type_description\") == 'CHANGED COURT DATE') |\n",
    "             (col(\"inspection_type_description\") == 'TASK FORCE NOT READY') |\n",
    "             (col(\"inspection_type_description\") == 'LICENSE/NOT READY') |\n",
    "             (col(\"inspection_type_description\") == 'Special Events (Festivals)') |\n",
    "             (col(\"inspection_type_description\") == 'citation re-issued') |\n",
    "             (col(\"inspection_type_description\") == 'LICENSE REQUEST') |\n",
    "             (col(\"inspection_type_description\") == 'Not Ready') |\n",
    "             (col(\"inspection_type_description\") == 'LIQOUR TASK FORCE NOT READY') |\n",
    "             (col(\"inspection_type_description\") == 'NO ENTRY-SHORT COMPLAINT)') |\n",
    "             (col(\"inspection_type_description\") == 'CANVASS SPECIAL EVENTS') |\n",
    "             (col(\"inspection_type_description\") == 'Task Force Liquor Catering') |\n",
    "             (col(\"inspection_type_description\") == 'Sample Collection') |\n",
    "             (col(\"inspection_type_description\") == 'REINSPECTION OF CLOSE-UP') |\n",
    "             (col(\"inspection_type_description\") == 'error save') |\n",
    "             (col(\"inspection_type_description\") == 'Non-Inspection') |                          \n",
    "             (col(\"inspection_type_description\") == 'Special Task Force') |\n",
    "             (col(\"inspection_type_description\") == 'TASTE OF CHICAGO') |\n",
    "             (col(\"inspection_type_description\") == 'POSSIBLE FBI') |\n",
    "             (col(\"inspection_type_description\") == 'RE-INSPECTION OF CLOSE-UP') |\n",
    "             (col(\"inspection_type_description\") == 'HACCP QUESTIONAIRE') |\n",
    "             (col(\"inspection_type_description\") == 'expansion') |\n",
    "             (col(\"inspection_type_description\") == 'Task Force Not-For-Profit Club') |\n",
    "             (col(\"inspection_type_description\") == 'CORRECTIVE ACTION') |\n",
    "             (col(\"inspection_type_description\") == 'REINSPECTION') \\\n",
    "             , 1).otherwise(0)\n",
    "\n",
    "df2 = df2.filter(x_col != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inspections_to_drop = df2.groupby(col(\"inspection_type_description\")).count().filter(col(\"count\") <= 30) \\\n",
    "#    .select(\"inspection_type_description\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inspections_to_drop = [str(i.inspection_type_description) for i in inspections_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df2.where(df2[\"inspection_type_description\"] == array(*[x for x in inspections_to_drop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select(\"inspection_type_description\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78769"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use StringIndexer to create a categorical feature from Inspection Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"inspection_type_description\", outputCol=\"inspection_type\").fit(df2)\n",
    "df2 = indexer.transform(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Inspection Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string2Date = udf (lambda s: datetime.strptime(s, '%m/%d/%y'), DateType())\n",
    "df2 = df2.withColumn(\"inspection_dt\", string2Date(df2[\"inspection_date_string\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year(inspection_dt)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year(inspection_dt)\n",
       "0                 2015\n",
       "1                 2013\n",
       "2                 2014\n",
       "3                 2012\n",
       "4                 2016\n",
       "5                 2010\n",
       "6                 2011"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick sanity check\n",
    "df2.select(year(\"inspection_dt\")).distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.persist(pyspark.StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week and Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"weekday_description\", date_format(col(\"inspection_dt\"), \"E\"))\n",
    "df2 = df2.withColumn(\"month\", month(col(\"inspection_dt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"weekday_description\", outputCol=\"weekday\").fit(df2)\n",
    "df2 = indexer.transform(df2)\n",
    "\n",
    "#note: month is already numerically indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding \"Did you pass last time?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df2.withColumn('prev_fail', \n",
    "                        lag(df2['y_fail'], count=1, default=0) #1 row back and return 0 is no first inspection (no rows back)\n",
    "                         .over(Window.partitionBy(df2[\"license_id\"])\n",
    "                             .orderBy(df2[\"inspection_dt\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_test = df_test.withColumn(\"prev_fail\", coalesce(df_test.prev_fail, lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['license_id',\n",
       " 'risk_description',\n",
       " 'zip',\n",
       " 'inspection_date_string',\n",
       " 'y_description',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'y',\n",
       " 'y_fail',\n",
       " 'reinspection',\n",
       " 'recent_inspection',\n",
       " 'task_force',\n",
       " 'special_event',\n",
       " 'canvass',\n",
       " 'liquor',\n",
       " 'fire',\n",
       " 'complaint',\n",
       " 'license_related',\n",
       " 'inspection_type_description',\n",
       " 'risk',\n",
       " 'inspection_type',\n",
       " 'inspection_dt',\n",
       " 'weekday_description',\n",
       " 'month',\n",
       " 'weekday',\n",
       " 'prev_fail']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn('cumulative_failures', \n",
    "                        sum(df_test['y_fail'])\n",
    "                         .over(Window.partitionBy(df_test[\"license_id\"])\n",
    "                             .orderBy(df_test[\"inspection_dt\"])\n",
    "                              .rowsBetween(-sys.maxsize,0))) #all previous up to the current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cumulative_failures=0),\n",
       " Row(cumulative_failures=7),\n",
       " Row(cumulative_failures=6),\n",
       " Row(cumulative_failures=9),\n",
       " Row(cumulative_failures=5),\n",
       " Row(cumulative_failures=1),\n",
       " Row(cumulative_failures=10),\n",
       " Row(cumulative_failures=3),\n",
       " Row(cumulative_failures=12),\n",
       " Row(cumulative_failures=8),\n",
       " Row(cumulative_failures=11),\n",
       " Row(cumulative_failures=2),\n",
       " Row(cumulative_failures=4),\n",
       " Row(cumulative_failures=13),\n",
       " Row(cumulative_failures=14),\n",
       " Row(cumulative_failures=15),\n",
       " Row(cumulative_failures=16)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.select(\"cumulative_failures\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Have you ever failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn(\"ever_failed\", when(col(\"cumulative_failures\") != 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Cumulative Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn('cumulative_inspections', \n",
    "                        count(df_test[\"inspection_dt\"]).over(Window.partitionBy(df_test[\"license_id\"])\n",
    "                              .orderBy(df_test[\"inspection_dt\"])\n",
    "                              .rowsBetween(-sys.maxsize,0))) #all previous up to the current one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Proportion of Fails to Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.withColumn(\"proportion_past_failures\", col(\"cumulative_failures\")/col(\"cumulative_inspections\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(license_id=u'1042702', risk_description=u'Risk 1 (High)', zip=u'60614', inspection_date_string=u'8/27/10', y_description=u'Pass', latitude=u'41.93041201', longitude=u'-87.64388653', y=1, y_fail=0, reinspection=0, recent_inspection=0, task_force=0, special_event=0, canvass=1, liquor=0, fire=0, complaint=0, license_related=0, inspection_type_description=u'Canvass', risk=1, inspection_type=0.0, inspection_dt=datetime.date(2010, 8, 27), weekday_description=u'Fri', month=8, weekday=2.0, prev_fail=0, cumulative_failures=0, ever_failed=0, cumulative_inspections=1, proportion_past_failures=0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Number of Days Since Last Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_lag = df_test.withColumn('last_inspection_dt',                         \n",
    "                        lag(df_test['inspection_dt'], count=1) \n",
    "                        .over(Window.partitionBy(df_test[\"license_id\"])\n",
    "                        .orderBy(df_test[\"inspection_dt\"])))\n",
    "\n",
    "df_test = df_lag.withColumn('days_since_last_inspection', \n",
    "                        datediff(df_lag.last_inspection_dt, df_lag.inspection_dt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop('last_inspection_dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save our Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('license_id', 'string'),\n",
       " ('risk_description', 'string'),\n",
       " ('zip', 'string'),\n",
       " ('inspection_date_string', 'string'),\n",
       " ('y_description', 'string'),\n",
       " ('latitude', 'string'),\n",
       " ('longitude', 'string'),\n",
       " ('y', 'int'),\n",
       " ('y_fail', 'int'),\n",
       " ('reinspection', 'int'),\n",
       " ('recent_inspection', 'int'),\n",
       " ('task_force', 'int'),\n",
       " ('special_event', 'int'),\n",
       " ('canvass', 'int'),\n",
       " ('liquor', 'int'),\n",
       " ('fire', 'int'),\n",
       " ('complaint', 'int'),\n",
       " ('license_related', 'int'),\n",
       " ('inspection_type_description', 'string'),\n",
       " ('risk', 'int'),\n",
       " ('inspection_type', 'double'),\n",
       " ('inspection_dt', 'date'),\n",
       " ('weekday_description', 'string'),\n",
       " ('month', 'int'),\n",
       " ('weekday', 'double'),\n",
       " ('prev_fail', 'int'),\n",
       " ('cumulative_failures', 'bigint'),\n",
       " ('ever_failed', 'int'),\n",
       " ('cumulative_inspections', 'bigint'),\n",
       " ('proportion_past_failures', 'double'),\n",
       " ('days_since_last_inspection', 'int')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cql\n",
    "CREATE  KEYSPACE chicago_data \n",
    "   WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor' : 1};\n",
    "```\n",
    "\n",
    "```cql\n",
    "CREATE TABLE chicago_data.inspections (\n",
    "    license_id text,\n",
    "    risk_description text,\n",
    "    zip text,\n",
    "    inspection_date_string text,\n",
    "    inspection_type_description text,\n",
    "    y_description text,\n",
    "    latitude text,\n",
    "    longitude text,\n",
    "    y int,\n",
    "    y_fail int,\n",
    "    reinspection int,\n",
    "    recent_inspection int,\n",
    "    task_force int,\n",
    "    special_event int,\n",
    "    canvass int,\n",
    "    fire int,\n",
    "    liquor int,\n",
    "    complaint int,\n",
    "    license_related int,\n",
    "    inspection_type int,\n",
    "    risk int,\n",
    "    inspection_dt date,\n",
    "    prev_fail int,\n",
    "    cumulative_failures int,\n",
    "    weekday_description text,\n",
    "    month int,\n",
    "    weekday int,\n",
    "    ever_failed int,\n",
    "    cumulative_inspections int,\n",
    "    proportion_past_failures double,\n",
    "    days_since_last_inspection int,\n",
    "    PRIMARY KEY (license_id, inspection_dt))\n",
    "WITH CLUSTERING ORDER BY (inspection_dt DESC);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " df_test.write\\\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .mode('append')\\\n",
    "    .options(table=\"inspections\", keyspace=\"chicago_data\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
